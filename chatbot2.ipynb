{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsIgUabEfckJ",
        "outputId": "5490c42e-41a4-4e88-eb72-44593cc7b29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setup Complete!\n",
            "PyTorch Version: 2.9.0+cpu\n",
            "Device Available: cpu (If 'cuda', your training will be super fast)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "# making chatbot with bigger intents file\n",
        "\n",
        "import nltk\n",
        "import torch\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"\\nSetup Complete!\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"Device Available: {device} (If 'cuda', your training will be super fast)\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile nltk_utils.py\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer=PorterStemmer()\n",
        "\n",
        "\n",
        "def tokenize(sentence):\n",
        "  return nltk.word_tokenize(sentence)\n",
        "\n",
        "\n",
        "# a=\"what is your name?\"\n",
        "# b=tokenize(a)\n",
        "# print(b)\n",
        "\n",
        "\n",
        "def stem(word):\n",
        "  return stemmer.stem(word.lower())\n",
        "\n",
        "\n",
        "# a=['organized','organizes',\"organizer\"]\n",
        "# b=[stem(word) for word in a]\n",
        "# print(b)\n",
        "\n",
        "\n",
        "\n",
        "def bag_of_words(tokenized_sentence,word):\n",
        "  tokenized_sentence=[stem(w)for w in tokenized_sentence]\n",
        "  bag=np.zeros(len(word),dtype=np.float32)\n",
        "\n",
        "\n",
        "  for idx,word in enumerate(word):\n",
        "    if word in tokenized_sentence:\n",
        "      bag[idx]=1.0\n",
        "  return bag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTCCPIxVgBDT",
        "outputId": "139888ab-2551-4b67-d552-7dc8d29f1f92"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing nltk_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet,self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "    self.l1=nn.Linear(input_size,hidden_size)\n",
        "\n",
        "\n",
        "    self.l2=nn.Linear(hidden_size,hidden_size)\n",
        "\n",
        "\n",
        "    self.l3=nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.l1(x)\n",
        "\n",
        "    out=self.relu(out)\n",
        "\n",
        "\n",
        "    out=self.l2(out)\n",
        "\n",
        "\n",
        "\n",
        "    out=self.relu(out)\n",
        "\n",
        "\n",
        "    out=self.l3(out)\n",
        "\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgScu7KTj-lW",
        "outputId": "30f4774e-9ed4-469c-e1b0-4058fa10255f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    }
  ]
}