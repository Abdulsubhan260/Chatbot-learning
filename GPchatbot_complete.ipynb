{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc9_V6KRGhND",
        "outputId": "4ce0c85a-c6f7-4569-8d67-48e61ba9c5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "with open('intents.json', 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "\n",
        "tags = []\n",
        "for intent in intents['intents']:\n",
        "    tags.append(intent['tag'])\n",
        "tags = sorted(set(tags))\n",
        "\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        encoded = tokenizer(\n",
        "            pattern,\n",
        "            add_special_tokens=True,\n",
        "            max_length=20,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "\n",
        "        input_ids.append(encoded['input_ids'][0])\n",
        "        attention_masks.append(encoded['attention_mask'][0])\n",
        "\n",
        "        label_ids = tags.index(intent['tag'])\n",
        "        labels.append(label_ids)\n",
        "\n",
        "\n",
        "input_ids = torch.stack(input_ids)\n",
        "attention_masks = torch.stack(attention_masks)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self, encodings, mask, labels):\n",
        "\n",
        "        self.encodings = encodings\n",
        "        self.mask = mask\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        return {\n",
        "            'input_ids': self.encodings[idx],\n",
        "            'attention_mask': self.mask[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "dataset = ChatDataset(input_ids, attention_masks, labels)\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "\n",
        "class Bert_Arch(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super(Bert_Arch, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n",
        "        # for param in self.bert.parameters():\n",
        "        #     param.requires_grad = False\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(768, output_dim)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        output = self.bert(sent_id, attention_mask=mask)\n",
        "        cls_vector = output.pooler_output\n",
        "        x = self.fc(self.dropout(cls_vector))\n",
        "        return x\n",
        "\n",
        "output_dim = len(tags)\n",
        "model = Bert_Arch(output_dim)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        sent_id = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        loss = cross_entropy(preds, labels)\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "output_data = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"output_dim\": output_dim,\n",
        "    \"tags\": tags,\n",
        "    \"vocab_size\": len(tokenizer),\n",
        "    \"embed_dim\": 768,\n",
        "    \"hidden_size\": 768,\n",
        "    \"max_len\": 20\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.save(output_data, \"bert_data.pth\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U8VEokMEK5jK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2665b36-9625-43a7-8294-672fe7cab3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFKO3niZUIuH",
        "outputId": "fa59b67a-eedb-4049-8631-71220b5f83c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-31 07:40:18.019864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769845218.039303    1504 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769845218.045066    1504 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769845218.059667    1504 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769845218.059692    1504 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769845218.059696    1504 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769845218.059699    1504 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-31 07:40:18.064068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 356kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 539kB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 997kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 5.16MB/s]\n",
            "model.safetensors: 100% 440M/440M [00:05<00:00, 74.1MB/s]\n",
            "Epoch 20/50 | Loss: 0.4678\n",
            "Epoch 40/50 | Loss: 0.0339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile chat.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer,BertModel\n",
        "import json\n",
        "import random\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "with open('intents.json','r') as f:\n",
        "  intents=json.load(f)\n",
        "\n",
        "File=torch.load('bert_data.pth')\n",
        "\n",
        "\n",
        "model_state=File['model_state']\n",
        "\n",
        "output_dim=File['output_dim']\n",
        "tags=File['tags']\n",
        "\n",
        "class Bert_Arch(nn.Module):\n",
        "  def __init__(self,output_dim):\n",
        "    super(Bert_Arch,self).__init__()\n",
        "    self.bert=BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    self.dropout=nn.Dropout(0.1)\n",
        "    self.fc=nn.Linear(768,output_dim)\n",
        "\n",
        "  def forward(self,sent_ids,mask):\n",
        "\n",
        "\n",
        "    output=self.bert(sent_ids,attention_mask=mask)\n",
        "    cls_vector=output.pooler_output\n",
        "\n",
        "    X=self.fc(self.dropout(cls_vector))\n",
        "\n",
        "    return X\n",
        "\n",
        "model=Bert_Arch(output_dim)\n",
        "model.load_state_dict(model_state)\n",
        "\n",
        "model=model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "bot_name=\"sam\"\n",
        "\n",
        "while True:\n",
        "  sentence=input('you: ')\n",
        "  if sentence=='quit':\n",
        "    break\n",
        "\n",
        "  encoded=tokenizer(\n",
        "      sentence,\n",
        "      add_special_tokens=True,\n",
        "      max_length=20,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_tensors='pt'\n",
        "  )\n",
        "\n",
        "\n",
        "  ids=encoded['input_ids'].to(device)\n",
        "  mask=encoded['attention_mask'].to(device)\n",
        "\n",
        "\n",
        "  output=model(ids,mask)\n",
        "\n",
        "  _,pred=torch.max(output,dim=1)\n",
        "\n",
        "  tag=tags[pred.item()]\n",
        "\n",
        "  prob=torch.softmax(output,dim=1)\n",
        "\n",
        "  prob=prob[0][pred.item()]\n",
        "\n",
        "\n",
        "  # print(f\"DEBUG: Top Prediction: '{tag}' | Confidence: {prob.item():.4f}\")\n",
        "\n",
        "  if prob.item() > 0.50:\n",
        "    for intent in intents['intents']:\n",
        "      if tag == intent['tag']:\n",
        "        print(f'{bot_name}: {random.choice(intent[\"responses\"])}')\n",
        "\n",
        "        break\n",
        "  else:\n",
        "\n",
        "    print(f'{bot_name}: I do not understand... (Low confidence: {prob.item():.2f})')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dLMGKca9Z6NU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583c8d1c-b340-4fcf-a5ce-b16b704e7ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting chat.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python chat.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND-PAaU0bmOH",
        "outputId": "eae74650-5d28-4b14-aa2b-cca1ba668734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-31 07:42:20.771524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769845340.790515    2136 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769845340.796394    2136 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769845340.811318    2136 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769845340.811344    2136 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769845340.811348    2136 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769845340.811353    2136 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-31 07:42:20.815953: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "you: hello\n",
            "sam: Hi there! Nice to see you.\n",
            "you: what is your name?\n",
            "sam: I am a Chatbot built with Python and PyTorch.\n",
            "you: how are you?\n",
            "sam: Alhamdulillah, I am doing great! Thanks for asking.\n",
            "you: weather update\n",
            "sam: It's always cool inside the server room! ‚ùÑÔ∏è\n",
            "you: tell me about pakistan\n",
            "sam: It is the land of the pure, founded in 1947.\n",
            "you: capital of pakistan\n",
            "sam: It used to be Karachi, but now it is the beautiful city of Islamabad.\n",
            "you: independence day of pakistan\n",
            "sam: Pakistan celebrates Independence Day on 14th August 1947.\n",
            "you: national animal of pakistan\n",
            "sam: The national animal of Pakistan is the Markhor (a large wild goat). üêê\n",
            "you: national sport of pakistan\n",
            "sam: The national sport is Field Hockey, even though cricket is more famous! üèë\n",
            "you: what is cricket\n",
            "sam: It is a sport with 11 players per side.\n",
            "you: who is imran khan\n",
            "sam: Imran Khan is a legend.\n",
            "you: who is babar azam\n",
            "sam: Babar Azam is the King! üëë\n",
            "you: tell me a joke\n",
            "sam: Why did the developer go broke? Because he used up all his cache! \n",
            "you: iam feeling hungry\n",
            "sam: Robots don't eat, but I hear Chicken Tikka is great.\n",
            "you: more information about pakistan\n",
            "sam: Pakistan is known for its hospitality, cricket, and delicious food.\n",
            "you: Pakistan bird\n",
            "sam: The national bird is the Chukar Partridge (Chakoor). üê¶\n",
            "you: shukriya\n",
            "sam: My pleasure!\n",
            "you: quit\n"
          ]
        }
      ]
    }
  ]
}